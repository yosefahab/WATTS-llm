{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyZ1spoZhD-6"
      },
      "source": [
        "# WATTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reBe0q1whD--"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEg6ZzD3hD--",
        "outputId": "afae7d3c-0cf1-4064-ca7b-d319e2c4888d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch as pt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seOckQ-0hD-_"
      },
      "source": [
        "### Hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "85tzf2UdhD-_"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 1000\n",
        "LR = 0.0003\n",
        "BATCH_SIZE = 64\n",
        "CONTEXT_SIZE = 128\n",
        "EVAL_EPOCHS = 100\n",
        "DROPOUT=0.2\n",
        "NUM_TRANSFORMER_BLOCKS = 6\n",
        "EMBEDDING_SIZE = 384\n",
        "NUM_HEADS = 6\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjratEf4hD_A"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FQr905HhD_A",
        "outputId": "80f858dd-02e8-46db-f05b-39c5d208d8c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x120493c50>"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "plt.style.use(\"dark_background\")\n",
        "def get_device():\n",
        "  \"\"\"\n",
        "  Returns the appropriate device for PyTorch training/inference.\n",
        "  Prioritizes CUDA, then MPS, and finally CPU.\n",
        "  \"\"\"\n",
        "  # Check for CUDA availability\n",
        "  if pt.cuda.is_available():\n",
        "    return pt.device(\"cuda\")\n",
        "  # Check for MPS availability (Apple Silicon only)\n",
        "  elif pt.backends.mps.is_available():\n",
        "    return pt.device(\"mps\")\n",
        "  # Default to CPU\n",
        "  else:\n",
        "    return pt.device(\"cpu\")\n",
        "\n",
        "# Example usage\n",
        "DEVICE = get_device()\n",
        "\n",
        "pt.manual_seed(1999)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "lfxsx5QkhD_B"
      },
      "outputs": [],
      "source": [
        "def plot_hist(*args):\n",
        "  for x in args:\n",
        "    plt.plot(x[0], x[1])\n",
        "  plt.title('Loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('loss')\n",
        "  plt.legend(['train', 'validation'], loc='upper right')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJWhK7OEhD_B"
      },
      "source": [
        "### Data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "XKfP4eCchD_C"
      },
      "outputs": [],
      "source": [
        "def load_dataset(path: str, train_frac=0.9, train=True):\n",
        "  \"\"\"\n",
        "  To load all data, pass train_frac=1 and train=False\n",
        "  otherwise pass the fraction of the dataset to be used for training, and specify train=True|False to get the first (train_frac) % or last (1 - train_frac) %\n",
        "  This allows to load only the specific dataset when needed to avoid memory hogging\n",
        "  \"\"\"\n",
        "  with open(path, \"r\") as f:\n",
        "      talks = json.load(f)\n",
        "\n",
        "      total_samples = len(talks) # total 117 talks\n",
        "      train_samples = int(total_samples * train_frac)\n",
        "      if train:\n",
        "          data = talks[0:train_samples]\n",
        "      else:\n",
        "          data = talks[train_samples:total_samples]\n",
        "      return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "hAwgFo2CjVZk"
      },
      "outputs": [],
      "source": [
        "def preprocess_dataset(dataset):\n",
        "  \"\"\"\n",
        "  returns the entire dataset concatenated into a single string\n",
        "  \"\"\"\n",
        "  merge_json_datapoint = lambda x: x[\"tag\"] + \" \" + x[\"title\"] + \" \" + x[\"body\"] # combine each title, tag and body of a talk\n",
        "  dataset = [merge_json_datapoint(x).strip() for x in dataset]\n",
        "  # merge into one text block\n",
        "  dataset = \" \".join(dataset)\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prPeFiCvvzUe",
        "outputId": "8b215757-7305-4225-f86b-62ffccb6f6d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: data: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir data && curl https://raw.githubusercontent.com/Can-Sahin/alanwatts-transcripts/master/transcripts.json -o data/transcripts.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "S1OnOX2bhD_C"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(105,\n",
              " {'title': 'Not What Should Be',\n",
              "  'body': 'I wonder what you mean, when you use the word ‘I?’ I’ve been very interested in this problem for a long long time, and I’ve come to the conclusion, that what most civilized people mean by that word, is a hallucination. That is to say, a false sense of personal identity, that is at complete variance with the facts of nature. And as a result of having a false sense of identity we act in a way that is inappropriate to our natural environment. And when that inappropriate way of action is magnified by a very powerful technology, we swiftly begin to see the results of a profound discord between man and nature. As is well known we are now in the process of destroying our environment, as a result, of an attempt to conquer it and master it. And we have not realized, therefore, that our environment is not something other than ourselves. In assuming that it is we have made a great mistake. And are now paying the price for it.\\n\\n \\n\\nBut most people would agree with the lines of the poet who said “I, a stranger and afraid, in a world I never made,” because we have the strong sensation that our own being inside our skin is extremely different from the world outside our skin. That while there may be intelligence inside human skins. And while there may be values and loving feelings. Outside the skin is a world of mechanical process which does not give a damn about any individual, and which is basically unintelligent. Being gyrations of blind force, and so far as the merely biological world is concerned gyrations of libido, which is Freud’s word for blind lust. It should be obvious, that the human being goes with the rest of the universe. Even though we say in popular speech “I came into this world.”\\n\\n \\n\\nNow it is not true that you came into this world. You came out of it. In the same way as a flower comes out of a plant or fruit comes out of a tree. And as an apple tree apples. The solar system in which we live and therefore the galaxy in which we live and therefore the system of galaxies in which we live. That system peoples. And therefore people are an expression of its energy and of its nature. If people are intelligent. And I suppose we have to grant that. If. Then the energy which people express must also be intelligent because one does not gather. Figs from thistles and grapes from thorns. But it does not occur you see to the ordinary civilized person to regard himself or herself. As an expression of the whole universe. It should be obvious that we cannot exist except in an environment of Earth, Air, Water, and solar temperature. That all these things go with us. And are as important to us albeit outside our skins as our internal or organs heart stomach brain and so forth.\\n\\n \\n\\nNow if then we cannot describe the behavior of organisms without at the same time describing the behavior of their environments we should realize that we have a new entity of description. Not the individual organism alone but what would now be called a field of behavior which we must call rather clumsily the organism environment. You go with your environment in the same way as your head goes with the rest of your body. You do not find in nature faces arriving in the world sui generous. They go with a body that also bodies do not arrive in a world. Which would be for example a plain ball of scrubbed rock floating without an atmosphere far away from a star. That will not grow bodies there is no soil for bodies. There is no complexity of environment which is body producing.\\n\\nSo bodies go with a very complicated natural environment and if the head goes with the body and the body goes with the environment the body is as much an integral part of the environment as the head is part of the body. It is deceptive of course because the human being is not rooted to the ground like a tree. A human being moves about and therefore can shift from one environment to another but the shifts are superficial the basic environment of the planet remains a constant and if the human being leaves the planet he has to take with him and a canned version of the planetary environment. Now we are not really aware of this upon taking thought and due consideration it does occur to us, yes indeed, we do need that environment but in the ordinary way we don’t feel it. That is to say we don’t have a vivid sensation of belonging to our environment in the same way that we have a vivid sensation of being an ego inside a bag of skin located mostly in the skull about halfway between the ears and a little way behind the eyes. And it issues in these disastrous results of the ego which according to one thousand century commonsense feels that it is a fluke in nature. And that if it does not fight nature it will not be able to maintain its status as intelligent fluke.\\n\\n \\n\\nSo the geneticists are now saying and many others are now saying that man must take the course of his evolution into his own hands. He can no longer trust the wiggly random and unintelligible processes of nature to develop him any further but he must interfere with his own intelligence. And through genetic alterations breed the kind of people who will be viable for human society and that sort of thing. Now this I submit is a ghastly era. Because human intelligence has a very serious limitation. That limitation is. That it is a scanning system, of conscious attention, which is linear. That is to say, it examines the world, in lines. Rather as you would pass the beam of a flashlight across a room or a spotlight. That’s why our education takes so long. It takes so long because we have to scan miles of lines of print. And we regard that you see as basic information.\\n\\n \\n\\nNow the universe does not come at us in lines. It comes at us. In a multidimensional continuum in which everything is happening all together everywhere at once. And it comes at us much too quickly, to be translated into lines of print. Or of other information, however fast they may be scanned. And that is our limitation so far as the intellectual life and the scientific life is concerned. The computer will greatly speed up the linear scanning. But it’s still linear scanning. And so long as we are stuck with that form of wisdom we cannot deal with more than a few variables at once. Now what do I mean by that. What is a variable? A variable is any one linear process let’s take music when you play a bar few. And there are four parts to it you have four variables you have four moving lines and you can take care of that with two hands. An organist using two feet can put into more variables and have six going and you may realize if you’ve ever tried to play the organ that it’s quite difficult to make six independent motions go at once. The average person cannot do that without training the average person cannot deal with more than three variables at once without using a pencil. Now when we study physics we are dealing with processes in which there are millions of variables. This however we handle by statistics in the same way as insurance companies use actuarial tables to predict when most people will die. If the average age of death is sixty five however, this prediction does not apply to any given individual. Any given individual will live to plus or minus sixty five years. And the range of difference may be very wide indeed of course. But this is all right the sixty five guesses all right when you’re doing large scale gambling. And that’s the way the physicist works in predicting the behavior of nuclear wavicles. But the practical problems of human life deal with variables in the hundreds of thousands. Here statistical methods are very poor. And thinking it out by linear consideration is impossible. With that equipment then we are proposing to interfere with our genes. And with that equipment also be it said we are trying to solve our political economic and social problems. And naturally everybody has the sense of total frustration. And the individual feels ‘what what on earth can I do? ‘\\n\\n \\n\\nWe do not seem to know a way of calling upon our brains. Because our brains can handle an enormous number of variables that are not accessible to the process of conscious attention your brain is now handling your total nervous system to be more accurate. Your blood chemistry; the secretions from your glans. The behavior of millions of cells. It is doing all that without thinking about it. That is to say, without translating the processes it is handling into consciously reviewed words, symbols or numbers. Now when I use the word thinking I mean precisely that process: translating. What is going on in nature in two words symbols. Or numbers because both words and numbers are kinds of symbols. Symbols bear the same relation to the real world that money bears to wealth. You cannot quench anybody’s thirst with the word water, just as you cannot eat a dollar bill and derive nutrition from it. But using symbols and using conscious intelligence; scanning, has proved very useful to us. It has given us such technology as we have. But at the same time it has proved too much of a good thing. At the same time, we’ve become so fascinated with it that we confuse the world as it is with the world as it is thought about talked about and figured about. That is to say, with the world as it is described.\\n\\n \\n\\nAnd the difference between these two is vast. And when we are not aware of ourselves except in a symbolic way. We are not related to ourselves at all we are like people eating menus instead of dinners. And that’s why we all feel psychologically frustrated. So then we get back to the question of, “What do we mean by I? ” Well first of all obviously we mean our symbol of ourselves. Now ourselves in this case is the whole psycho physical organism conscious and unconscious, plus its environment. That’s your real self. Your real self. In other words, is the universe as centered on your organis. That’s you.\\n\\n \\n\\nLet me just clarify that a little for one reason. What you do is also a doing of your environment. Your behavior is its behavior as much as it’s behavior is your behavior. It’s mutual. We could say it is transactional. You are not a puppet which your environment pushes around. Nor is the environment a puppet which you push around. They go together they act together. In the same way for example if I have a wheel one side of it going down is the same as the other side of it going up. When you handle the steering wheel of a car, are you pulling it or are you pushing it? No, you’re doing both, aren’t you? When you pull it down the side you are pushing it up that side. It’s all one so there’s a push pull between organism and environment. We are only rarely aware of this as when in curious alterations of consciousness which we call mystical experience, cosmic consciousness, an individual gets the feeling that everything that is happening is his own doing. Or the opposite of that feeling that he isn’t doing anything, but that all his doings his decisions and so forth are happenings of nature. You can feel it either way. You can describe it in these two completely opposite ways but you’re talking about the same experience you’re talking about experiencing your own activity and the activity of nature as one single process. And you can describe it as if you were omnipotent like God or as if it were completely deterministic and you hardly existed at all. But remember both points of view are right. And we’ll see where that gets us.\\n\\n \\n\\nBut we don’t feel that do we, ordinarily? What we feel instead is an identification of ourselves with our idea of ourselves or I would rather say with our image of ourselves? And that’s the person. Or the ego. You play a role, you identify with that role. I play a role, it’s called Alan Watts and I know very well that that’s a big act. I can play some other roles besides Alan Watts, if necessary. But I find this one is better for making a living. But I assure you it’s a mask and I don’t take it seriously. The idea of my being a kind of messiah or guru or savior of the world just breaks me up. Because I know me. You know it’s very difficult to be holy. In the ordinary sense. So I know I’m not that but most of us are taught to think that we are whom we are called. And, when you are a little child and you begin to learn a role and your parents and your peers approve of your be. In that they know who you are. You’re predictable, so you can be controlled. But when you act out of role and you imitate some other child’s behavior everybody points the finger and says you’re not being true to yourself. “Johnny, that’s not you, that’s Peter.” And so you learn to stay Peter. Or to stay Johnny. But of course you’re not either. Because this is just the image of you it’s as much of you as you can get into your conscious attention, which is precious little. Your image of yourself contains no information about how you structure your nervous system. It contains no information about your blood chemistry it contains almost no information about the subtle influences of society upon your behavior. It does not include the basic assumptions of your culture which are all taken for granted and unconscious. And you can’t find them out unless you study other cultures to see how their basic assumptions differ. It includes all kinds of illusions that you’re completely unaware of as for example that time is real.\\n\\n \\n\\nAnd that there is such a thing as a past. Which is pure hokum. But there are nevertheless all these things that are unconscious in us and they are not included in our image of ourselves, nor of course included in our image of ourselves is there any information about our inseparable relationships with the whole natural universe. So this is a very impoverished image. When you ask a person “what did you do yesterday? ” They’ll give you a historical account of a certain number of events in which they participated in, the certain number of things which they saw, used or were clubbed by. But realize at once that this history leaves out most of what happened. I in trying to describe what happens to me this evening will never be able to describe because there are so many people here that if I were to talk about everyone whom I’ve seen what they were wearing what color there was what sort of expressions they had on their faces I would have to talk to doomsday. So instead of this rich physical experience, which is very rich indeed I have to attenuate it in memory and description to saying “Oh I met a lot of people in Philadelphia. And they were men and the women a lot of them were young and some of them were old.” You know, it’s an utterly impoverished account of what went on. So therefore in thinking of ourselves in this way what I did yesterday what I did the day before in terms of this stringing mangy account all I have is a caricature of myself. And you know the caricaturist doesn’t draw you all in he just put certain salient features whereby people will recognize you. As sort of a skeleton. So we can see we are as it were conceiving ourselves as a bunch of skeletons and they’ve got no flesh on, just a bunch of bones. And no wonder we all feel inadequate. We’re all looking for something, to the future, to bring us the goodie. We know we ought to have. There’s a golden goodie at the end of the line somewhere there’s a good time coming. Be it ever so way far away that one far off divine event which all creation moves we hope. And therefore we say of something that’s no good it has no future. I would say it has no present. But everybody says it has no future.\\n\\n \\n\\nNow, here we are, as it were, psychically starved. And always there for looking for looking seeking seeking seeking. And this confused seeking is going on everywhere we don’t know what we want. Nobody knows what they want. We say yes we think we think of what we want in vague terms: pleasure, money, wealth, love. Fulfillment personal development. But we don’t know what we mean by all that. The person really sits down to figure out write out, I say twenty pages, on your idea of heaven. It will be a sorry production. You can see it already in Medieval art whether it’d pictures of heaven and hell. Hell is always much better than Heaven. Although it’s uncomfortable it’s a sadomasochistic orgy. Wowie, you know hell is really a rip roaring, whereas all the saints in heaven are sitting, of the with you know, very very smug and demure like they were in church. And you see also the multitudes of the saved instead of this writhing wormy thing you can see all their heads which the artist is drawn to abbreviate them just the tops of their heads in masses they look like cobblestone street. Flattened out. So what has happened then is this. That I. Is an illusion it’s an image and it is no more ourself than an idol is the god. But we say it can’t be so, because I feel I really exist, it isn’t just an idea in my head, it’s a feeling, I feel me! Well what is it that you feel when you feel I?\\nWhat is it that you feel when you feel I? I’ll tell you. What do you do when somebody says “Pay attention!” What is the difference between looking at something and taking a hard look at it? And between hearing something and listening intently? What’s the difference? What’s the difference between waiting while something goes on and enduring it. Why? The difference is this that when you pay attention instead of just looking you screw up your face you frown. And stare that is a muscular activity around here. When you will, you grit your teeth or clench or this when you endure or control yourself you pull yourself together,physically,  and therefore you get uptight. You hold your breath, you do all kinds of muscular things to control the functioning of your nervous system and none of them have the slightest effect on the proper operation of the nervous system. If you stare at things, you will rather fuzz the image than see them clearly if you listen intently by concentrating on muscles around the ears you will be so much attending to muscles here that you won’t hear things properly and you may get singing in the ears. If you tighten up with your body to pull yourself together, all you do is constrict yourself. I remember in school I sat next to a boy who had great difficulty in learning to read. And what they always say to children is “try!” If you can do something as tries so the boy tries to muddy done when he’s trying to get out words he grunts and groans as if he were lifting weights. And the teachers impress the boys really trying gives him B for effort. Has nothing to do with it.\\n\\n \\n\\nNow we all make this muscular strain, with the thought that it’s achieving psychological results. The sort of psychological results it’s intended to achieve and all this amounts to is this like you’re taking off on a jet plane you’ve gone a mile down the runway and the thing is not in the air yet, and you get nervous, so you start pulling at your seatbelt. That’s what it is. Now that is a chronic feeling we have it us all the time and it corresponds to the word I. That’s what you feel when you say I. You feel that chronic tension because when an organ is working properly you don’t feel it. If you see your eye you’ve got cataract. If you hear your ears, you’ve got singing in the areas you know getting in the way of hearing. When you of fully functioning, you are unaware of the organ. When you are thinking clearly your brain isn’t getting in your way. Actually of course you are seeing your eyes in the sense that everything you see out in front of you is a condition in the optic nerves at the back of the skull. That’s where you’re aware of all this, but you’re not aware of the I as the I. I’m talking about the optical eye.\\n\\n \\n\\nSo when we are aware of the ego I we are aware of this chronic tension inside ourselves and that’s not us, it’s a futile tension. So when we get the illusion the image of ourselves married to a futile tension you’ve got an illusion married to a futility. And then you wonder why I can’t do anything. Why I feel in the face of all the problems of the world impotent, and why I somehow cannot manage to transform I? Now here we get to the real problem, because we’re always telling each other that we should be different. I’m not going to tell you that tonight. Why not, because I know you can’t be. Nor can I. That may sound depressing but I’ll show you it isn’t, it’s very heartening. But everybody you see who is at all sensitive, and awake to their own problems and human problems is trying to change himself. We know we can change the world unless we change ourselves if we are all individually selfish we’re going to be collectively selfish. If we don’t really love people and only pretend to, somehow we’ve got to find a way to love. After all it’s said in the Bible that our shalt love the Lord thy God. And your neighbor as yourself. You must love. We all agree sure. But we don’t. In fact one psychologist very smartly asked the patient with whom are you in love against.\\n\\n \\n\\nAnd this is particularly becomes appalling when we enter into the realm of higher things by which I mean spiritual development. Everybody these days is interested in spiritual development. And wisely because we want to change our consciousness. Many people are well aware that this egocentric consciousness is a hallucination. And that they presume it’s the function of religion to change it because that’s what the Zen Buddhists and yogis and all these people in the Orient to doing. They’re changing their state of consciousness to get something called Satori, all mystical experience or Nirvana or moksha or what have you and everybody around here has a really enthused about that because you don’t get that in church. I mean that has been Christian mystics but the church has been very quiet about them.\\n\\n \\n\\nThen the average church all you get is talk. There’s no meditation, no spiritual discipline, they tell God what to do interminably as if he didn’t know. And then they tell the people what to do as if they could or even wanted to. And then they sing religious nursery rhymes. And then to cap it all the Roman Catholic Church, which did at least have an unintelligible service which was… Which was you know it was real mysterious and suggested bad magic was going on there when put the thing into bad English. And they took away incense and they took away they became a bunch of Protestants and there was a terrible So now all these Catholics are at loose ends it’s clear booth loosed put it up to be a pun but she said you know. It’s no longer possible to practise contemplative prayer mats. As you’re being advised, exhausted, edified all the time.\\n\\n \\n\\nAnd it becomes a bore. Think of God listening to all those prayers. We do have I mean talking about grieving the Holy Spirit. It’s just awful. People have no consideration for God at all. So. But in pursuing these spiritual disciplines yoga and Zen and so forth and also psychotherapy there comes up a big difficulty. And the big difficulty is this. I want to find a method whereby I can change my consciousness. But the, therefore to improve myself, but then the self that needs to be improved is the one that is doing the improving.\\n\\n \\n\\nAnd so I’m rather stuck. I found out the reason that I think I believe say in god, is that I sure hope that somehow God will rescue me. In other words, I want to hang on to my own existence and I feel rather shaky about doing that for myself but I just hope there’s a God who’ll take care of it. Or if I could be loving. I would have a better opinion of myself. I feel better about it I could face myself as people say. If I were more loving so the unloving me somehow by some gimmickry has to turn itself into a loving me and this is just like trying to lift yourself off the ground with your own bootstraps. It can’t be done.  And that’s why religion in practice mainly produces hypocrisy. And guilt. Because of the constant failure of these enterprises. People go and study Zen. And they come back and say wow getting rid of your ego is a superhuman task. I assure you it’s going to be very very difficult to get rid of your ego you have to sit for a long time and you’re going to get the sorest legs. It’s hard work and all you wretched kids you think you’re getting rid of your ego on part or something or other and easy yoga you don’t know what you’re in for when it really comes down to the nitty gritty.\\n\\nBut you know the biggest ego trip going is getting rid of your ego. And the joke of it all is your ego doesn’t exist. There’s nothing to get rid of. It’s an illusion as I tried to explain. But you still want to ask how to stop the illusion. And who’s asking? I mean, do you think in the ordinary sense in which you use the word ‘I’, how can I stop identify myself with the wrong me? But the answer is simply you can’t. The Christians put this in their way when they say that mystical experience is a Gift of Divine Grace. Man as such cannot achieve this experience it is a gift of God and if God doesn’t give it to you there’s no way of getting it. Now that is solidly true. You can’t do anything about it because you don’t exist. Well you say that’s pretty depressing news.\\n\\n \\n\\nBut the whole point is it isn’t depressing news, it is the joyous news! There’s a Zen poem which puts it like this talking about it, it means the mystical experience the Satori, the realisation that you are the eternal energy of the universe like Jesus did. It says like this you cannot catch hold of it nor can you get rid of it. In not being able to get it you get it. When you speak, it is silent, when you are silent it speaks. Now in not being able to get it you get it because this whole feeling what Krishnamurthi is trying to explain to people, for example, when he says why do you ask for a method there is no method all methods are simply gimmicks for strengthening your ego.\\n\\n \\n\\nSo how do we not do that this is you’re still asking for a method there is no method if you really understand what your ‘I’ is you will see there is no method. This is so so sad. But it’s not this is the gospel the good news. Because if you cannot achieve it if you cannot transform yourself. That means that the main obstacle to mystical vision has collapsed. That was you. What happens you can’t do anything about. You’re at your wit’s end. What are you going to do, commit suicide? But supposing you just put that off for a little while. Wait and see what happens. You can’t control your thoughts, you can’t control your feelings. Because there is no control. You are your thoughts and your feelings and they’re running along running along running along to sit and watch them. There they go you’re still breathing aren’t you. Still growing your hair. Still seeing and hearing. Are you doing that? I mean is breathing something that you do? Do you see I mean do you organize the operations of your eyes and know exactly how to work those rods and cones in the retina? Do you do that? It’s a happening. It happens so you can feel all this happening. You are breathing it’s happening, your thinking is happening, you’re feeling is happening you’re hearing you’re seeing the clouds are happening across the sky the sky is happening blue the sun is happening shining.\\n\\n \\n\\nThere it is. All this happening. And may I introduce you, this is yourself. This begins to be a vision of who you really are. And that’s the way you function you function by happening that is to say by spontaneous occurrence. And this is not a state of affairs that you should realise. I cannot possibly preach it to you because the minute you start thinking I should understand that this is the stupid notion again that I should bring it about when there is no you to bring it about so that’s why I’m not preaching you can only preach to egoss.\\n\\n \\n\\nAll I can do is to talk about what is. It amuses me to talk about what it is because it’s wonderful. I love it and therefore I like to talk if I get paid for it. And I make my living and sensible people get paid for doing what they enjoy doing. So this is not an easy this is the whole approach is not to convert you not to make you over not to improve you but for you to discover if you really knew the way you are, things would be would be sane. But you see you can’t do that. You can’t make that discovery because you’re in your own way. So long as you think “I’m I.” So long as that hallucination knocks it. And the hallucination disappears only in the realisation of its own futility. When at last you see you can’t do it. You cannot make yourself over, you cannot really control your own mind. See, when we try to control the mind. A lot of yoga teachers try to get you to control your own mind mainly to prove to you that you can’t do it. There’s nothing, you know a fool who persists in his folly will become wise, so they what they do is they speed up the folly. And so you get concentrating. And you can have a certain amount of superficial and initial success by a process commonly called self-hypnosis. And you can think you’re making progress. And a good teacher will let you go along that way for a while until he really throws you with one. Why are you concentrating?\\n\\n \\n\\nBuddhism works this way, Buddha said if you suffer you suffer because you desire and your desires are either unattainable or always being disappointed or something. So cut out desire. So those disciples went away and they stamped on desire jumped on desire cut the throat of desire and threw out desire but then they came back and but as said but you are still desiring not to desire. It. I wonder how to get rid of that so when you see that that’s nonsense they are naturally comes over you a quietness. In seeing that you cannot control your mind, you realize there is no control. What you took to be the thinker of thoughts is just one of the thoughts what you took to be the feeler of the feelings which was that chronic muscular strain was just one of the feelings. What you took to be the experience of experience is just part of the experience.\\n\\n \\n\\nSo there isn’t any thinker of thoughts feel or feelings we get into that bind because we have a grammatical rule that verbs have to have subjects. And the funny thing about that is that verbs are processes and subjects and nouns which are supposed to be things how does a noun start a verb. How does the thing put a process into action. Obviously it can’t. But we always insist that there is this subject called the knower. And without a knower there can’t be knowing. Well that’s just a grammatical rule it isn’t the rule of nature. In nature there’s just knowing like you’re feeling it and how to say you are feeling it as if you were somehow different from the feeling when I say I am feeling I what I mean is there is feeling here. When I say you are feeling I mean there is feeling there. I have to say even “There is feeling. What a cumbersome language we have. Chinese is easier you don’t have to put all that in writing that why you can say things twice as fast in Chinese as you can in any other language.\\n\\n \\n\\nWell anyway. When you come to see that you can do nothing that the play of thought of feeling etc just goes on by itself as a happening. Then you are in a state which we will call meditation. And slowly. Without being pushed your thoughts will come to silence that is to say all the verbal symbolic chatter going on in the skull. Don’t try and get rid of it. Because that will again produce the illusion that there’s a controller. Just, it goes on it goes on it goes on finally it gets tired of itself and bored and stops. And so then there’s a silence. And this is a deeper level of meditation. And in that silence. You suddenly begin to see the world as it is. And you don’t see any past. And you don’t see any future. You don’t see any difference between yourself and the rest of it that’s just an idea you can put your hand on the difference between myself and you. You know you can’t blow it, you can’t bounce it, you can’t pull it. It’s just an idea. You can’t find any material body. Because material body is an idea, so is spiritual body, somebody is philosophical notions see reality isn’t material. That’s an idea reality isn’t spiritual That’s an idea reality is [claps].\\n\\n \\n\\nSo we find, if I’ve got to put it back into words that we live in an eternal now. You’ve got all the time in the world because you’ve got all the time there is which is now. And you are this universe. And you feel this strange feeling when when when ideas don’t define the differences you feel that other people’s doings or your doings. And that makes it very difficult to blame other people. If you’re not sophisticated theologically You may of course run screaming in the streets and say that you’re God.\\n\\n \\n\\nIn a way that’s what happened to Jesus because he wasn’t sophisticated theologically he only had Old Testament Biblical theology behind him. If he’d had Hindu theology he could have put it more subtly. But it was only that rather primitive theology of the Old Testament. And that was a conception of God as a monarchical boss. And you can’t go around sandboxes son. If you’re going to say “I’m God,” you must allow it for everyone else too. But this was a heretical idea from the point of view of Hebrew theology and so what they did with Jesus was they pedestalised him, I mean they kicked him upstairs so that he wouldn’t be able to influence anyone else and only you maybe god. And that stopped the Gospel cold right at the beginning. It couldn’t spread.\\n\\n \\n\\nWell anyway. This is therefore to say that the transformation of human consciousness through meditation is frustrated so long as we think of it in terms of something that I myself can bring about. By some kind of wangled, by some sort of gimmick. Because you see that leads to endless games of spiritual one upmanship. And of guru competitions, of my guru is more effective than your guru, my yoga faster than your yoga, I’m more aware of myself than you are I’m humbler than you are I’m sorry for my sins than you are I love you more than you love me it is interminable goings on about which people fight and wonder whether they’re a little bit more evolved than somebody else and so on all that can just fall away. And then. We get this strange feeling that we have never had to see in our lives except occasionally by accident some people get a glimpse. That we are no longer. This poor little stranger and afraid in a world it never made. But that you are this universe and you are creating it at every moment because YOU SEE IT STARTS NOW. It didn’t begin in the past there was no past so if the universe began in the past when that happened it was now, see. But it’s still now and the universe is still beginning now and it’s trailing off like the wake of a ship from now in the wake of the ship fades out so does the past. You can look back there to explain things but the explanation disappears, you never find things are not explained by the past or explained by what happens now. That creates the past and it begins here. That’s the birth of responsibility. Because otherwise you can always look over your shoulder and say well I’m the way I am because my mother dropped me and she dropped me because she was neurotic because a mother dropped her, and away we go back to Adam and Eve, to disappearing monkey or something and we never get at iit. But in this way you’re faced with it you’re doing all this. And it’s an extraordinary shock. So. Cheer up. You can’t blame anyone else for the kind of world you’re in. And if you know you see that I, in the sense of the person, the front, the ego really doesn’t exist. Then it won’t go to your head too badly if you wake up and discover that your god.',\n",
              "  'tag': 'Tao of Philosophy'},\n",
              " 12,\n",
              " {'title': 'Gateless Gate',\n",
              "  'body': 'When I originally planned [this] series of talks, I had not intended to include what to me is one of the most remarkable books in the world. And the reason I hadn’t originally intended to include it in the series, is that, to the average person who is not acquainted with these matters it’s a book of extraordinary difficulty, despite the fact that from another point of view, it’s a very simple book. But in any rate, I thought I’d have a shot at it. This book is called in its Chinese title Wu Min Guan. And literally translated that means no-gate barrier. Or you might call it the gateless gate, or the gate which is no gate. The book is representative of an extremely important school of Buddhism known as a Zen in Japanese and as charm in Chinese. And this particular school of Buddhism has been one of the most potent influences. In the history of Far Eastern culture, in the shaping of its arts and such a wide range of Arts, going from painting and calligraphy at one extreme to the art of Jujutsu at the other. Including in between, landscape architecture ordinary house architecture ceramics archery, fencing, all kinds of things as well as daily life itself. And because of them has been of such great influence in forming the cultures of the Far East is one of the most important types of oriental philosophy for us to understand. \\n\\n \\n\\nBut when one comes to the literature of Zen, the beginner is faced with a very strange problem. And the problem is that the great majority of this literature consists of anecdotes store is which are technically called Mondo or question and answer. And these story is are somewhat like jokes. Because a joke strikes you as funny only if you get the punchline see the point and laugh at once. If somebody has to draw a diagram and explain the joke to you and tell you just why it’s funny, well, it falls flat. And it’s the same with these stories. There is a meaning to them, but this meaning is not a symbolic meaning as I will try and explain in a little while you don’t really have to be in the know about a kind of subtle and obscure system of symbols in order to be able to interpret them. The strange thing about these stories is that the point which they convey is so obvious, that it’s difficult to see. And the problem about explaining a book of this kind is that the more I might succeed in giving you what would seem to you like a convincing and satisfactory explanation, the more I should be fooling you why would that be well for exactly the same reason. As if I were explaining jokes. If I explain a joke and draw a diagram of it I cheat you out of the laugh. You will never have a belly laugh over it, you will at most have a rather polite throaty laugh but if I do not explain the point of a joke to you, even if you do not see the point immediately it is told some time later while you’re ruminating over it the point may suddenly occurred to you and then you may get the benefit of laughter. However the point of these then stories is not so much to make you laugh. But to create a state of mind which in some respects is rather similar to laughter in that it is a state of profound feeling it’s not just a state of understanding words. And that profound feeling is called in the technical language of zen Buddhism, Satori. And Satori is more literally, a sudden awakening. I think when I was talking about the Diamond Sutra. I tried to give some explanation of what is meant in Buddhism by awakening. I’m not going to try and give a further definition of what it means, except by agency of the stories themselves and some comments about them. But awakening, is the goal of all Buddhist endeavor. It is a kind of psychotherapy a kind of transformation of the consciousness of the everyday person which is held to be a sleep, into a state of awakening, in which you might say he is so clearly conscious of reality. That he is never fooled anymore by the illusions of life. \\n\\n \\n\\nBefore I turn to the actual story is contained in our book The no-gate barrier, I think I should say something by way of introduction about Zen itself because then it is really an extraordinary phenomena in the history of philosophy and religion. The reason why Zen is so peculiar is that it has to begin with no doctrines that can be stated in words nothing that it requires anybody to believe. It has no system of formulated philosophy. In fact, it doesn’t really have anything to say at all. What is remarkable about zen is that it endeavors to convey its message. The realisation which constitutes awakening in Buddhism, without the intermediary of words and ideas. There are four statements which sum up the character of Zen Buddhism and they are as follows. A direct transmission of awakening outside the Scriptures. No dependence on words and letters. Direct pointing. And finally, seeing into one’s own nature and becoming a Buddha, which is to say, an awakened one. I particularly want to concentrate on what is meant for the moment by direct pointing, because this is the technique in which Zen excels. Zen feels that all that human beings are seeking all that they really fundamentally desire. Whether it be complete contentment of the heart, understanding why this universe exists and what our place in it is all this understanding is not something obscure and far off, but something completely obvious. And lying open for us to anybody who cares to look at it in this immediate moment which we are living now it does as if to say. The whole secret of life everything that you could possibly desire is yours at this moment. And if you cannot lay hold on it now you will never be able to. The difficulty is that it’s very hard to convince people of this by talking about it because all talk, all systems of ideas, are in relation to reality itself somewhat like a menu in relation to a dinner. And those who try to get comfort to get wisdom out of books or by believing in various systems of ideas and philosophies. Such people are really devouring the menu instead of eating the dinner. \\n\\n \\n\\nNow how then is one to divert people’s attention from the main you to the dinner itself. There’s only one way and that is to point directly at the dinner to stop talking about it to stop writing about it and to point out it directly. And this is what zen does and most of these stories from the no gate barrier Wu Min Guan, the examples of direct pointing. According to legend the Zen school of Buddhism was introduced into China in about the five hundred twenty seven A.D.. By a sage. From India whose name was Bodhi Dharma. And Bodhidharma is always represented in the art of the Far East as a fierce gentleman with a bushy beard and staring bright eyes. In Japan, at the present time children’s toys are made to represent body Dharma their little fellows rather like the American schmoo. Same sort of shape, and their weighted inside you know they’re legless figures and they’re weighted inside so that you can’t knock them over they’re always come up right again. And always, there is the fierce stare in the eyes of the bushy beard on the chin and of course there is some reference to body dharmas secret to the teaching which he brought, to the message of Zen in the fact that you can’t not was little fella over you can push it in this way you could push him that, but he always bobs up again. The first story I’m going to read from the Wu Min Guan, which incidentally was compiled by a teacher of the Zen school who lived in China between eleven hundred eighty three and twelve sixty. The first story I’m going to read you is the story of the encounter between Bodhi Dharma and his first disciple. Whose name was Aka. Bodhidharma was sitting facing the wall. His future successor a car stands in the snow. And presents his severed arm to Bodhidharma I should explain in parenthesis that. Bodhidharma had very much discouraged from becoming his disciple and this is always the way with Oriental philosophical and spiritual teachers they don’t look for disciples. And the reason why. Bodhi Dharma wasn’t looking for disciples was his own fundamental feeling that he had nothing to teach the truth of Buddhism was so completely obvious that anyone could see it if he looked and to talk about it and try and teach it was as they say in Zen, only to put legs on a snake. You know, a snake walks very well without legs and if you stuck some on it would only embarrass him. And so he had said repeatedly I have nothing to teach go away. But a guy was so convinced that Bodhidharma had some secret which he could convey to him that at last as a token of sincerity he cut off one of his arms while standing outside the teacher’s heart in the freezing snow and presented it to the teacher crying. My mind is not pacified. Master, pacify my mind. Bodhi Dharma says, If you bring me that mind, I will pacify it for you. I said. When I search for my mind, I cannot hold it. Bodhi Dharma said then your mind is pacified already. And it is said that at this moment a car had a sudden insight into the whole mystery of life, the problem of peace of mind and the essential meaning of Buddhism itself. To each one of these stories, the editor of the book has added a comment and a poem, and I’m going to read the comment which he’s put here. ‘That broken toothed Hindu Bodhidharma came thousands of miles over the sea from India to China as if he had something wonderful. He is like raising waves without wind. After he remained years in China he had only one disciple and that one lot. Does Armin was deformed alas ever since he has had brainless disciples.’ And the poem. Why did Bodhi Dharma come to China. For years monks have discussed this. All the troubles that have followed since came from that teacher and disciple. It’s a characteristic convention of zen literature that the masters of the school poke fun at one another. Because insofar as they seem to be masters they all realize that calling themselves masters is kind of a joke because a mass there is after all one who has something to teach and in Zen, there is nothing to teach. The more one teaches them all one tries to explain it the more obscure it becomes just like the more one explains the joke or less funny it becomes. Going back to the story about bodhiDharma and Aka, Aka is expressing a very ordinary, simple human problem. He says, I have no peace of mind what does he mean by mind. We might say so we might say ego or self. I feel that I am happy I need peace. \\n\\n \\n\\nAnd so BodhiDharma says very naturally, bring up this soul, this mind of yours and I’ll pass if I had. But Aka says you know when I try to find myself. I can’t. I look and look. But then I realize that I’m looking for the one who is looking and I can never lay hold on it. But body Dharma said there your mind is pacified already. I feel very diffident, really, about making any comment was story of that kind, but just in the nature of a little bit of a hint. We are all very convinced indeed that we exist as a kind of self or ego. And our selfishness is one of our major problems. It would, wouldn’t it, be rather fascinating, to find that when we look for ourselves we are not really there. As if where we expected to find ourselves in the center of all our experience we found only a hole, an empty space. And then the problem of myself, my happiness my peace of mind. Would have disappeared. There is no one whom one has to pacify whom one has to make happy. You’re not actually there. But of course one can’t discover that just by hearing about it you have to look and see that’s why one of the fundamental questions in oriental philosophy is the simple question Who are you? Look and try to find out who it is that is trying to find out who it is that is trying to find out. This is after all. A parable of what everybody is doing who is engaged in what we in the west call self-seeking. And this is really a stupid as somebody sitting down in a chair and bashing him gnashing away trying to bite his own teeth. Well then here’s another story from the no gate area. There was once a teacher called Tozan. And one day when he was weighing some flax, a student came to him and said, What is Buddha? This question can mean, What is reality? Or what is it to be awakened? Tozan answered, This flax weighs three pounds. Period. Then I read your comment. Old tows arms then there’s like a clam. The minute the shell opens you see the hole inside. However I want to ask youm Do you see the real Tozan? And then the poem. Three pounds of flax in front of your nose close enough and the mind is still closer. Whoever talks about affirmation and negation lives in the right and wrong region. \\n\\n \\n\\nNow you must not suppose that there is some symbolism in saying this flax weighs three pounds. Or why I know some commentators have tried to explain that in Buddhism there are three precious jewels the Buddha himself the dharma or his doctrine and the Sangha, or his ordained followers. But the three pounds of flax don’t refer to the three jewels turns on answered. This flax weighs three pounds, just as you might answer a very simple question about where are you going to say when I’m going in town to buy groceries. Or, what kind of a day was it yesterday? Where you live only to say it was raining a good deal of the time. And this flax weighs three pounds there’s an answer just like that but it seems doesn’t that a strange answer to give to a question like What is reality or what is it to be fully awakened? Well, Zen teachers say that they derived this tradition of answering questions in that direct simple way from the Buddha himself, because our book contains a story. That this was the way in which the border passed on. The secret of his own teaching to his principal disciple whose name was Mahaghashaba. \\n\\n \\n\\nAnd this is the story: When the Buddha was in the greed Rockwood the mountain he turned a flower in his fingers and held it before his lessons. Everyone was silent. Only Mahaghashaba smiled that this revelation although he tried to control the lines of his face. The Buddha said. I have the eye of the true teaching. The heart of Nirvana, of awakening, the true aspect of the formless. The ineffable stride of the doctrine. It is not expressed by words, but especially transmitted beyond teaching. This teaching I now give to my how to shop. And then, the very amusing commentary of Wuman, Golden-faced Buddha, thought he could cheat anyone. He made the good listeners as bad and so dog meat under the sign of mutton. And he himself thought it was wonderful whatever the audience had laughed together. How could he have transmitted the teaching? And again if market because shot my shop I had not smiled How could he have transmitted the teaching. If he says that realisation can be transmitted he is like a city slicker that cheats the country dub. And if he says it cannot be transmitted Why does he approve of Mahaghashaba. \\n\\n \\n\\nAnd then the poem: At the turning of a flower his disguise was exposed no one in heaven and can surpass my hookah shoppers wrinkled face. There were all those disciples gathered around the Buddha expecting from him the usual daily words of wisdom and instead of that he said nothing. He just picked up a flower and held it in his hand. And this is the same sort of answer. That tones on gave when he was asked what is reality he just said. This lacks weighs three pounds. An ordinary statement just as holding up a flower is an ordinary action. When Zen teaches began to answer questions about reality in this way, they had their imitators. Those who thought that they had got hold of something, that [it] was you know a sort of new cultish fad in the way of religion and they went around imitating these kind of antics in order to seem wise and to collect followers but this is what happened to a person and try that sort of thing is this. Dorie called Gutei. Gutei raised his finger whenever he was asked a question about zen. A boy attendant began to imitate him in this way. When anyone asked the boy what his master had preached about, the boy would raise his finger. Gutei heard about the boy’s Mr. He seized him. And asked him the question. What is the fundamental principle of Buddhism the boy raised his finger and at once Butei cut it off. The boy cried out, and ran away. But Gutei called out and stopped him. When the boy turned his head to good a. Gutei raised up his own finger. In that instant, the boy was enlightened. When Gutei was about to pass from as well he gathered his monks around him. I attained my fingers and he said from my teacher ten real and in my whole life I could not exhaust it. And he passed away. \\n\\n \\n\\nSo the secret of the thing is not just in being able to do some strange antics in answer to questions, and the fellow who didn’t really understand but imitated his understanding got into very serious trouble. But despite of his get into trouble, he realized the thing in the end. Here is a story in which perhaps the point of this great a thing begins to come a little clearer. And it’s called The Story of tipping over the pitcher. Heakoto send him out to open a new ministry. He told his pupils that whoever answered a question most ably would be appointed. Placing a water pitcher on the ground he asked. Who can say what this is without calling its name? The chief monk said no one can call it a wooden shoe. But Isan, the cooking monk tipped over the pitcher with his foot and went out. Jaco just smiled and said the chief monk loses. And Isan became the master of the new ministry. Woman comments. Eason was brave enough but he could not escape Iago Joe’s trick. After all, he gave up a light job and took a heavy one why can’t you see he took off his comfortable hat and placed himself in iron stocks. If I talk all the time, and never listen to what others have to say I shall lose touch with my fellow man. In the same way, if I think all the time which is in a way talking to myself inwardly I shall lose touch with the reality with which words are about, which they’re intended to symbolize. It’s the fundamental inside of zen that by an excess of thinking men have lost touch with the real world in which they live. The solution to this problem is to be silent in one’s mind and to look again at the real world not thinking but seeing it directly this can’t be talked about. If I want you to listen to music any advice to do so will drown out the music the directness way is to play music itself. In other words, he had seen that the reality of the picture was not the word or the idea ‘picture’, but was something non-verbal. And by this action demonstrated that this was his understanding you cannot put what it is into words. And this indeed is a central point of zen and of Buddhist understanding in general. That reality is beyond words. And that one must not confuse the world of things as we think about them and talk about them and name them, with the world as it actually is. \\n\\n \\n\\nThe first story I read was a case in point. Because in the world of ideas and words and conceptions and inherited social notions every one of us is perfectly convinced that he is a self, an ego. But when we step out of that world of conventional ideas into the clear daylight of reality and with wide open eyes look for ourselves, what do we find?',\n",
              "  'tag': ''})"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ds = load_dataset(\"./data/transcripts.json\")\n",
        "eval_ds = load_dataset(\"./data/transcripts.json\", train=False)\n",
        "len(train_ds), train_ds[0], len(eval_ds), eval_ds[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsDTUnZikKoV",
        "outputId": "08765846-532e-49f3-e043-2ec250b5a459"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tao of Philosophy Not What Should Be I wonder what you mean, when you use the word ‘I?’ I’ve been very interested in this proble\n"
          ]
        }
      ],
      "source": [
        "train_ds = preprocess_dataset(train_ds)\n",
        "eval_ds = preprocess_dataset(eval_ds)\n",
        "print(train_ds[:CONTEXT_SIZE])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bxqv6_x1hD_D",
        "outputId": "e2f9f42e-38ee-41e7-924c-6f492a4f1760"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(168,\n",
              " '\\n !$&()+,-./0123456789:;=>?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_`abcdefghijklmnopqrstuvwxyz~\\xadàáäæçéêìíïñòóöùúûĀāąīŌōŚśūǎǐǒ̥ΘΥάεμξορςστअकतथमलवशसािे्ḍṃṅṇṛṣṭἄἌἱὁὸῦ–—‘’‚“”…事念悩无無煩爲碍')"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get vocab from train set\n",
        "vocab = sorted(list(set(train_ds)))\n",
        "VOCAB_SIZE = len(vocab)\n",
        "VOCAB_SIZE, \"\".join(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "js7KklWHhD_E"
      },
      "outputs": [],
      "source": [
        "stoi = {ch:i for i,ch in enumerate (vocab)} # string to int, used for encoding\n",
        "itos = {i:ch for i,ch in enumerate (vocab)} # int to string, used for decoding\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: \"\".join([itos[i] for i in l]) # decoder: take a list of integers, output a string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZnzzmD9hD_E",
        "outputId": "d9c5452e-e39e-42ef-8251-42c901d28128"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([34, 61, 68, 68, 71, 1, 49, 71, 74, 68, 60, 2], 'Hello World!')"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encode(\"Hello World!\"), decode(encode(\"Hello World!\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "FSfWzQiQli8l"
      },
      "outputs": [],
      "source": [
        "# Convert to tensors\n",
        "train_ds = pt.tensor(encode(train_ds), dtype=pt.long)\n",
        "eval_ds = pt.tensor(encode(eval_ds), dtype=pt.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "ajN0gfnmhD_E"
      },
      "outputs": [],
      "source": [
        "def get_batch(data, train=True):\n",
        "    \"\"\"\n",
        "    generate a small batch of data of inputs x and targets y\n",
        "    where x is a sequence of tokens, and y is the same sequence offset by 1 token.\n",
        "    \"\"\"\n",
        "    # get random number between 0 and len(data) - CONTEXT_SIZE, because we will take CONTEXT_SIZE tokens. Repeat BATCH_SIZE times\n",
        "    ix = pt.randint(len(data) - CONTEXT_SIZE, (BATCH_SIZE, ))\n",
        "    x = pt.stack([data[i:i+CONTEXT_SIZE] for i in ix])\n",
        "    y = pt.stack([data[i+1:i+CONTEXT_SIZE+1] for i in ix])\n",
        "    return x.to(DEVICE), y.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "K6NWMRxChD_F"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "when input is tensor([58], device='mps:0') the target: 71\n",
            "when input is tensor([58, 71], device='mps:0') the target: 77\n",
            "when input is tensor([58, 71, 77], device='mps:0') the target: 76\n",
            "when input is tensor([58, 71, 77, 76], device='mps:0') the target: 1\n",
            "when input is tensor([58, 71, 77, 76,  1], device='mps:0') the target: 76\n",
            "when input is tensor([58, 71, 77, 76,  1, 76], device='mps:0') the target: 64\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64], device='mps:0') the target: 61\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61], device='mps:0') the target: 1\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1], device='mps:0') the target: 75\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75], device='mps:0') the target: 59\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59], device='mps:0') the target: 65\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65], device='mps:0') the target: 61\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61], device='mps:0') the target: 70\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70],\n",
            "       device='mps:0') the target: 59\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59],\n",
            "       device='mps:0') the target: 61\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61],\n",
            "       device='mps:0') the target: 1\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1],\n",
            "       device='mps:0') the target: 71\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71],\n",
            "       device='mps:0') the target: 62\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62], device='mps:0') the target: 1\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1], device='mps:0') the target: 68\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68], device='mps:0') the target: 65\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65], device='mps:0') the target: 70\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70], device='mps:0') the target: 63\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63], device='mps:0') the target: 77\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77], device='mps:0') the target: 65\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65], device='mps:0') the target: 75\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75], device='mps:0') the target: 76\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76], device='mps:0') the target: 65\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65], device='mps:0') the target: 59\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59], device='mps:0') the target: 75\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75], device='mps:0') the target: 1\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1],\n",
            "       device='mps:0') the target: 71\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71],\n",
            "       device='mps:0') the target: 74\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74],\n",
            "       device='mps:0') the target: 1\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1],\n",
            "       device='mps:0') the target: 75\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75],\n",
            "       device='mps:0') the target: 61\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61], device='mps:0') the target: 69\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69], device='mps:0') the target: 57\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57], device='mps:0') the target: 70\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70], device='mps:0') the target: 76\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76], device='mps:0') the target: 65\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65], device='mps:0') the target: 59\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59], device='mps:0') the target: 75\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75], device='mps:0') the target: 1\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1], device='mps:0') the target: 79\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79], device='mps:0') the target: 61\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61], device='mps:0') the target: 1\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1], device='mps:0') the target: 69\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69], device='mps:0') the target: 65\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65],\n",
            "       device='mps:0') the target: 63\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63],\n",
            "       device='mps:0') the target: 64\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64],\n",
            "       device='mps:0') the target: 76\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76],\n",
            "       device='mps:0') the target: 1\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1],\n",
            "       device='mps:0') the target: 57\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57], device='mps:0') the target: 75\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75], device='mps:0') the target: 67\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67], device='mps:0') the target: 1\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1], device='mps:0') the target: 75\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75], device='mps:0') the target: 71\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71], device='mps:0') the target: 69\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69], device='mps:0') the target: 61\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61], device='mps:0') the target: 1\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1], device='mps:0') the target: 73\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73], device='mps:0') the target: 77\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77], device='mps:0') the target: 61\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61], device='mps:0') the target: 75\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75], device='mps:0') the target: 76\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76],\n",
            "       device='mps:0') the target: 65\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65],\n",
            "       device='mps:0') the target: 71\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71],\n",
            "       device='mps:0') the target: 70\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70],\n",
            "       device='mps:0') the target: 75\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75],\n",
            "       device='mps:0') the target: 1\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1], device='mps:0') the target: 57\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57], device='mps:0') the target: 58\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58], device='mps:0') the target: 71\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71], device='mps:0') the target: 77\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77], device='mps:0') the target: 76\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76], device='mps:0') the target: 1\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1], device='mps:0') the target: 76\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76], device='mps:0') the target: 64\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64], device='mps:0') the target: 61\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61], device='mps:0') the target: 1\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1], device='mps:0') the target: 76\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76], device='mps:0') the target: 81\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81], device='mps:0') the target: 72\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72],\n",
            "       device='mps:0') the target: 61\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61],\n",
            "       device='mps:0') the target: 1\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1],\n",
            "       device='mps:0') the target: 71\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71],\n",
            "       device='mps:0') the target: 62\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62],\n",
            "       device='mps:0') the target: 1\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1], device='mps:0') the target: 61\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61], device='mps:0') the target: 80\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80], device='mps:0') the target: 72\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80, 72], device='mps:0') the target: 61\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80, 72, 61], device='mps:0') the target: 74\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80, 72, 61, 74], device='mps:0') the target: 65\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80, 72, 61, 74, 65], device='mps:0') the target: 61\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80, 72, 61, 74, 65, 61], device='mps:0') the target: 70\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80, 72, 61, 74, 65, 61, 70], device='mps:0') the target: 59\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80, 72, 61, 74, 65, 61, 70, 59], device='mps:0') the target: 61\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80, 72, 61, 74, 65, 61, 70, 59, 61], device='mps:0') the target: 1\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80, 72, 61, 74, 65, 61, 70, 59, 61,  1], device='mps:0') the target: 62\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80, 72, 61, 74, 65, 61, 70, 59, 61,  1, 62], device='mps:0') the target: 74\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80, 72, 61, 74, 65, 61, 70, 59, 61,  1, 62, 74],\n",
            "       device='mps:0') the target: 71\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80, 72, 61, 74, 65, 61, 70, 59, 61,  1, 62, 74, 71],\n",
            "       device='mps:0') the target: 69\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80, 72, 61, 74, 65, 61, 70, 59, 61,  1, 62, 74, 71, 69],\n",
            "       device='mps:0') the target: 1\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80, 72, 61, 74, 65, 61, 70, 59, 61,  1, 62, 74, 71, 69,  1],\n",
            "       device='mps:0') the target: 79\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80, 72, 61, 74, 65, 61, 70, 59, 61,  1, 62, 74, 71, 69,  1, 79],\n",
            "       device='mps:0') the target: 64\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80, 72, 61, 74, 65, 61, 70, 59, 61,  1, 62, 74, 71, 69,  1, 79,\n",
            "        64], device='mps:0') the target: 65\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80, 72, 61, 74, 65, 61, 70, 59, 61,  1, 62, 74, 71, 69,  1, 79,\n",
            "        64, 65], device='mps:0') the target: 59\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80, 72, 61, 74, 65, 61, 70, 59, 61,  1, 62, 74, 71, 69,  1, 79,\n",
            "        64, 65, 59], device='mps:0') the target: 64\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80, 72, 61, 74, 65, 61, 70, 59, 61,  1, 62, 74, 71, 69,  1, 79,\n",
            "        64, 65, 59, 64], device='mps:0') the target: 1\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80, 72, 61, 74, 65, 61, 70, 59, 61,  1, 62, 74, 71, 69,  1, 79,\n",
            "        64, 65, 59, 64,  1], device='mps:0') the target: 76\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80, 72, 61, 74, 65, 61, 70, 59, 61,  1, 62, 74, 71, 69,  1, 79,\n",
            "        64, 65, 59, 64,  1, 76], device='mps:0') the target: 64\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80, 72, 61, 74, 65, 61, 70, 59, 61,  1, 62, 74, 71, 69,  1, 79,\n",
            "        64, 65, 59, 64,  1, 76, 64], device='mps:0') the target: 61\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80, 72, 61, 74, 65, 61, 70, 59, 61,  1, 62, 74, 71, 69,  1, 79,\n",
            "        64, 65, 59, 64,  1, 76, 64, 61], device='mps:0') the target: 74\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80, 72, 61, 74, 65, 61, 70, 59, 61,  1, 62, 74, 71, 69,  1, 79,\n",
            "        64, 65, 59, 64,  1, 76, 64, 61, 74], device='mps:0') the target: 61\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80, 72, 61, 74, 65, 61, 70, 59, 61,  1, 62, 74, 71, 69,  1, 79,\n",
            "        64, 65, 59, 64,  1, 76, 64, 61, 74, 61], device='mps:0') the target: 1\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80, 72, 61, 74, 65, 61, 70, 59, 61,  1, 62, 74, 71, 69,  1, 79,\n",
            "        64, 65, 59, 64,  1, 76, 64, 61, 74, 61,  1], device='mps:0') the target: 57\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80, 72, 61, 74, 65, 61, 70, 59, 61,  1, 62, 74, 71, 69,  1, 79,\n",
            "        64, 65, 59, 64,  1, 76, 64, 61, 74, 61,  1, 57], device='mps:0') the target: 74\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80, 72, 61, 74, 65, 61, 70, 59, 61,  1, 62, 74, 71, 69,  1, 79,\n",
            "        64, 65, 59, 64,  1, 76, 64, 61, 74, 61,  1, 57, 74], device='mps:0') the target: 71\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80, 72, 61, 74, 65, 61, 70, 59, 61,  1, 62, 74, 71, 69,  1, 79,\n",
            "        64, 65, 59, 64,  1, 76, 64, 61, 74, 61,  1, 57, 74, 71],\n",
            "       device='mps:0') the target: 75\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80, 72, 61, 74, 65, 61, 70, 59, 61,  1, 62, 74, 71, 69,  1, 79,\n",
            "        64, 65, 59, 64,  1, 76, 64, 61, 74, 61,  1, 57, 74, 71, 75],\n",
            "       device='mps:0') the target: 61\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80, 72, 61, 74, 65, 61, 70, 59, 61,  1, 62, 74, 71, 69,  1, 79,\n",
            "        64, 65, 59, 64,  1, 76, 64, 61, 74, 61,  1, 57, 74, 71, 75, 61],\n",
            "       device='mps:0') the target: 1\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80, 72, 61, 74, 65, 61, 70, 59, 61,  1, 62, 74, 71, 69,  1, 79,\n",
            "        64, 65, 59, 64,  1, 76, 64, 61, 74, 61,  1, 57, 74, 71, 75, 61,  1],\n",
            "       device='mps:0') the target: 76\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80, 72, 61, 74, 65, 61, 70, 59, 61,  1, 62, 74, 71, 69,  1, 79,\n",
            "        64, 65, 59, 64,  1, 76, 64, 61, 74, 61,  1, 57, 74, 71, 75, 61,  1, 76],\n",
            "       device='mps:0') the target: 64\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80, 72, 61, 74, 65, 61, 70, 59, 61,  1, 62, 74, 71, 69,  1, 79,\n",
            "        64, 65, 59, 64,  1, 76, 64, 61, 74, 61,  1, 57, 74, 71, 75, 61,  1, 76,\n",
            "        64], device='mps:0') the target: 61\n",
            "when input is tensor([58, 71, 77, 76,  1, 76, 64, 61,  1, 75, 59, 65, 61, 70, 59, 61,  1, 71,\n",
            "        62,  1, 68, 65, 70, 63, 77, 65, 75, 76, 65, 59, 75,  1, 71, 74,  1, 75,\n",
            "        61, 69, 57, 70, 76, 65, 59, 75,  1, 79, 61,  1, 69, 65, 63, 64, 76,  1,\n",
            "        57, 75, 67,  1, 75, 71, 69, 61,  1, 73, 77, 61, 75, 76, 65, 71, 70, 75,\n",
            "         1, 57, 58, 71, 77, 76,  1, 76, 64, 61,  1, 76, 81, 72, 61,  1, 71, 62,\n",
            "         1, 61, 80, 72, 61, 74, 65, 61, 70, 59, 61,  1, 62, 74, 71, 69,  1, 79,\n",
            "        64, 65, 59, 64,  1, 76, 64, 61, 74, 61,  1, 57, 74, 71, 75, 61,  1, 76,\n",
            "        64, 61], device='mps:0') the target: 1\n"
          ]
        }
      ],
      "source": [
        "# Display what the input to the model looks like at each step\n",
        "x, y = get_batch(train_ds) # (BATCH_SIZE, CONTEXT_SIZE)\n",
        "for b in range(BATCH_SIZE):\n",
        "    for t in range(CONTEXT_SIZE):\n",
        "        context = x[b, :t+1]\n",
        "        target = y[b, t]\n",
        "        print(f\"when input is {context} the target: {target}\")\n",
        "    break\n",
        "del x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE22mhoIma_F"
      },
      "source": [
        "### Train utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "1ipSvP0AmZz4"
      },
      "outputs": [],
      "source": [
        "@pt.no_grad\n",
        "def estimate_loss(model):\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ('train', 'eval'):\n",
        "        losses = pt.zeros(EVAL_EPOCHS)\n",
        "        for k in range(EVAL_EPOCHS):\n",
        "            X, Y = get_batch(train_ds if split == 'train' else eval_ds)\n",
        "            _, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "0naZh8U6md9y"
      },
      "outputs": [],
      "source": [
        "def train_model(model, optimizer):\n",
        "  history = {\"train_loss\": [], \"eval_loss\": []}\n",
        "  for epoch in range(EPOCHS):\n",
        "      if epoch % EVAL_EPOCHS == 0:\n",
        "          losses = estimate_loss(model)\n",
        "          history[\"train_loss\"].append(losses['train'])\n",
        "          history[\"eval_loss\"].append(losses['eval'])\n",
        "          print(f\"\\rEpoch: {epoch}, train loss: {losses['train']:.4f}, validation loss: {losses['eval']:.4f}\", end='')\n",
        "      xb, yb = get_batch(train_ds)\n",
        "      _, loss = model(xb, yb)\n",
        "      optimizer.zero_grad(set_to_none=True)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "  return (model, optimizer, history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgZPA97VhD_F"
      },
      "source": [
        "### Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPOgyCbLhD_F"
      },
      "source": [
        "#### GPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "BmnEExHrhD_G"
      },
      "outputs": [],
      "source": [
        "class AttentionHead(nn.Module):\n",
        "    def __init__(self, head_size, dropout=DROPOUT):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(EMBEDDING_SIZE, head_size, bias=False)\n",
        "        self.query = nn.Linear(EMBEDDING_SIZE, head_size, bias=False)\n",
        "        self.value = nn.Linear(EMBEDDING_SIZE, head_size, bias=False)\n",
        "        self.register_buffer('tril', pt.tril(pt.ones(CONTEXT_SIZE, CONTEXT_SIZE)))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, E = x.shape # (BATCH_SIZE, CONTEXT_SIZE, EMBEDDING_SIZE)\n",
        "        k = self.key(x)\n",
        "        q = self.query(x)\n",
        "        v = self.value(x)\n",
        "        w = q @ k.transpose(-2, -1) * E**-0.5 # scaled dot product\n",
        "        w = w.masked_fill(self.tril[:C, :C] == 0, float(\"-inf\")) # only take current context size tokens into consideration\n",
        "        w = pt.softmax(w, dim=-1)\n",
        "        w = self.dropout(w)\n",
        "        return w @ v # (B, C, C) @ (B, C, E) -> (B, C, E)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "wZVau420hD_G"
      },
      "outputs": [],
      "source": [
        "class MultiHeadedAttention(nn.Module):\n",
        "    def __init__(self, num_heads, head_size, dropout=DROPOUT):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([AttentionHead(head_size) for _ in range(num_heads)])\n",
        "        self.projection = nn.Linear(EMBEDDING_SIZE, EMBEDDING_SIZE)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    def forward(self, x):\n",
        "        x = pt.cat([h(x) for h in self.heads], dim=-1)\n",
        "        x = self.projection(x)\n",
        "        x = self.dropout(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Pcl32EXxhD_G"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, n_embed, dropout=DROPOUT):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embed, 4 * n_embed),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embed, n_embed),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "maM8R7jBhD_G"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, n_embed, n_head):\n",
        "        super().__init__()\n",
        "        head_size = n_embed // n_head\n",
        "        self.self_attn = MultiHeadedAttention(n_head, head_size)\n",
        "        self.ffwd = FeedForward(n_embed)\n",
        "        self.layer_norm1 = nn.LayerNorm(n_embed)\n",
        "        self.layer_norm2 = nn.LayerNorm(n_embed)\n",
        "    def forward(self, x):\n",
        "        x = x + self.self_attn(self.layer_norm1((x))) # residual connection (+x), pre-layer normalization (deviation from the paper)\n",
        "        x = x + self.ffwd(self.layer_norm2(x))\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0j4y82nhD_G",
        "outputId": "931716d2-8b00-4a16-c7fa-9d88ad558aed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "Layer (type:depth-idx)                        Param #\n",
            "======================================================================\n",
            "GPT                                           --\n",
            "├─Embedding: 1-1                              64,512\n",
            "├─Embedding: 1-2                              49,152\n",
            "├─Sequential: 1-3                             --\n",
            "│    └─TransformerBlock: 2-1                  --\n",
            "│    │    └─MultiHeadedAttention: 3-1         590,208\n",
            "│    │    └─FeedForward: 3-2                  1,181,568\n",
            "│    │    └─LayerNorm: 3-3                    768\n",
            "│    │    └─LayerNorm: 3-4                    768\n",
            "│    └─TransformerBlock: 2-2                  --\n",
            "│    │    └─MultiHeadedAttention: 3-5         590,208\n",
            "│    │    └─FeedForward: 3-6                  1,181,568\n",
            "│    │    └─LayerNorm: 3-7                    768\n",
            "│    │    └─LayerNorm: 3-8                    768\n",
            "│    └─TransformerBlock: 2-3                  --\n",
            "│    │    └─MultiHeadedAttention: 3-9         590,208\n",
            "│    │    └─FeedForward: 3-10                 1,181,568\n",
            "│    │    └─LayerNorm: 3-11                   768\n",
            "│    │    └─LayerNorm: 3-12                   768\n",
            "│    └─TransformerBlock: 2-4                  --\n",
            "│    │    └─MultiHeadedAttention: 3-13        590,208\n",
            "│    │    └─FeedForward: 3-14                 1,181,568\n",
            "│    │    └─LayerNorm: 3-15                   768\n",
            "│    │    └─LayerNorm: 3-16                   768\n",
            "│    └─TransformerBlock: 2-5                  --\n",
            "│    │    └─MultiHeadedAttention: 3-17        590,208\n",
            "│    │    └─FeedForward: 3-18                 1,181,568\n",
            "│    │    └─LayerNorm: 3-19                   768\n",
            "│    │    └─LayerNorm: 3-20                   768\n",
            "│    └─TransformerBlock: 2-6                  --\n",
            "│    │    └─MultiHeadedAttention: 3-21        590,208\n",
            "│    │    └─FeedForward: 3-22                 1,181,568\n",
            "│    │    └─LayerNorm: 3-23                   768\n",
            "│    │    └─LayerNorm: 3-24                   768\n",
            "├─LayerNorm: 1-4                              768\n",
            "├─Linear: 1-5                                 64,680\n",
            "======================================================================\n",
            "Total params: 10,818,984\n",
            "Trainable params: 10,818,984\n",
            "Non-trainable params: 0\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "class GPT(nn.Module):\n",
        "    \"\"\"\n",
        "    Decoder only transformer model\n",
        "    \"\"\"\n",
        "    def __init__(self, num_blocks=NUM_TRANSFORMER_BLOCKS):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(VOCAB_SIZE, EMBEDDING_SIZE)\n",
        "        self.pos_enc = nn.Embedding(CONTEXT_SIZE, EMBEDDING_SIZE)\n",
        "        self.blocks = nn.Sequential(\n",
        "            *[TransformerBlock(EMBEDDING_SIZE, 4) for _ in range(num_blocks)],\n",
        "        )\n",
        "        self.layer_norm = nn.LayerNorm(EMBEDDING_SIZE)\n",
        "        self.lang_model_head = nn.Linear(EMBEDDING_SIZE, VOCAB_SIZE) # language model head\n",
        "\n",
        "    def forward(self, context, targets=None):\n",
        "        \"\"\"\n",
        "        @param idx: (pytorch tensor) of shape (BATCH_SIZE, CONTEXT_SIZE)\n",
        "        @param target: (pytorch tensor) of shape (BATCH_SIZE, CONTEXT_SIZE)\n",
        "        \"\"\"\n",
        "        B, C = context.shape\n",
        "\n",
        "        token_embeds = self.embedding(context) # (BATCH_SIZE , CONTEXT_SIZE, EMBEDDING_SIZE)\n",
        "        pos_embeds = self.pos_enc(pt.arange(C, device=DEVICE))\n",
        "        x = token_embeds + pos_embeds\n",
        "        x = self.blocks(x)\n",
        "        x = self.layer_norm(x)\n",
        "        logits = self.lang_model_head(x) # (BATCH_SIZE , CONTEXT_SIZE, VOCAB_SIZe)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, C, V = logits.shape\n",
        "            logits = logits.view(B*C, V)\n",
        "            targets = targets.view(B*C)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, context, max_sentence_len):\n",
        "        \"\"\"\n",
        "        @param idx: (pytorch tensor) of shape (BATCH_SIZE, CONTEXT_SIZE), the context\n",
        "        \"\"\"\n",
        "        for _ in range(max_sentence_len):\n",
        "            logits, _ = self.forward(context[:, -CONTEXT_SIZE:])\n",
        "            logits = logits[:,-1,:]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            idx_next = pt.multinomial(probs, num_samples=1)\n",
        "            context = pt.cat((context, idx_next), dim=1)\n",
        "        return context\n",
        "\n",
        "print(summary(GPT()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91xm0BachD_H",
        "outputId": "0b886a02-c5b7-484a-e67a-a81fefc51ebe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "िæ\n",
            "=`yæεἱ悩òŚHĀúiतε\n",
            "Jp,P91XMpY9jōशfTΥICws$事8ṣ!cYññ+oǒ1m事PΥvUy念=zNμἄukûṭph–5R5‘:3ε4Qzἄ–̥ΘöNΘt’~lñἱὁNṭD`煩ì0ṇSlσZacxHNïPr事म事vρRwτἱṣ碍άGWMḍΘ”?Cj.äṣ[ḍρ/σἌथξ~e ्ö u-ि.Nṅ1~ṣμ_]ǐ7ρàrī碍`–F,ὁ–Θ’­無–τथ”PअCvéाτाḍû7-\n"
          ]
        }
      ],
      "source": [
        "model = GPT().to(DEVICE)\n",
        "pred = model.generate(pt.zeros((1,1), dtype=pt.long, device=DEVICE), 200)[0].tolist()\n",
        "optimizer = pt.optim.Adam(model.parameters(), lr=LR)\n",
        "print(decode(pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1oVXVwhn_Pn",
        "outputId": "c41aee9b-95e3-4bc1-8661-56404bf5989a"
      },
      "outputs": [],
      "source": [
        "model, optimizer, history = train_model(model, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "feyqWnTj0Mdy",
        "outputId": "98f9292a-a2c2-4b15-fcdb-e7fee6aff5f9"
      },
      "outputs": [],
      "source": [
        "plot_hist(*[([i for i in range(len(v))], v) for v in history.values()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pt.save(model.state_dict(), \"./models/\" + model.__class__.__name__ + \".pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "orP2c3HA7BF5"
      },
      "outputs": [],
      "source": [
        "def prompt(model: nn.Module, context):\n",
        "  model.eval()\n",
        "  encoded_str= encode(context)\n",
        "  encoded_str = pt.tensor(encoded_str, dtype=pt.long, device=DEVICE)\n",
        "  encoded_str=encoded_str.unsqueeze(0)\n",
        "  pred=model.generate(encoded_str, 100)[0].tolist()\n",
        "  model.train()\n",
        "  print(decode(pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "======================================================================\n",
              "Layer (type:depth-idx)                        Param #\n",
              "======================================================================\n",
              "GPT                                           --\n",
              "├─Embedding: 1-1                              64,512\n",
              "├─Embedding: 1-2                              49,152\n",
              "├─Sequential: 1-3                             --\n",
              "│    └─TransformerBlock: 2-1                  --\n",
              "│    │    └─MultiHeadedAttention: 3-1         590,208\n",
              "│    │    └─FeedForward: 3-2                  1,181,568\n",
              "│    │    └─LayerNorm: 3-3                    768\n",
              "│    │    └─LayerNorm: 3-4                    768\n",
              "│    └─TransformerBlock: 2-2                  --\n",
              "│    │    └─MultiHeadedAttention: 3-5         590,208\n",
              "│    │    └─FeedForward: 3-6                  1,181,568\n",
              "│    │    └─LayerNorm: 3-7                    768\n",
              "│    │    └─LayerNorm: 3-8                    768\n",
              "│    └─TransformerBlock: 2-3                  --\n",
              "│    │    └─MultiHeadedAttention: 3-9         590,208\n",
              "│    │    └─FeedForward: 3-10                 1,181,568\n",
              "│    │    └─LayerNorm: 3-11                   768\n",
              "│    │    └─LayerNorm: 3-12                   768\n",
              "│    └─TransformerBlock: 2-4                  --\n",
              "│    │    └─MultiHeadedAttention: 3-13        590,208\n",
              "│    │    └─FeedForward: 3-14                 1,181,568\n",
              "│    │    └─LayerNorm: 3-15                   768\n",
              "│    │    └─LayerNorm: 3-16                   768\n",
              "│    └─TransformerBlock: 2-5                  --\n",
              "│    │    └─MultiHeadedAttention: 3-17        590,208\n",
              "│    │    └─FeedForward: 3-18                 1,181,568\n",
              "│    │    └─LayerNorm: 3-19                   768\n",
              "│    │    └─LayerNorm: 3-20                   768\n",
              "│    └─TransformerBlock: 2-6                  --\n",
              "│    │    └─MultiHeadedAttention: 3-21        590,208\n",
              "│    │    └─FeedForward: 3-22                 1,181,568\n",
              "│    │    └─LayerNorm: 3-23                   768\n",
              "│    │    └─LayerNorm: 3-24                   768\n",
              "├─LayerNorm: 1-4                              768\n",
              "├─Linear: 1-5                                 64,680\n",
              "======================================================================\n",
              "Total params: 10,818,984\n",
              "Trainable params: 10,818,984\n",
              "Non-trainable params: 0\n",
              "======================================================================"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = GPT().to(DEVICE)\n",
        "model.load_state_dict(pt.load(\"./models/gpt.pt\"))\n",
        "summary(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjZMDxcohD_H",
        "outputId": "eafc1d5d-4cba-4cd1-9fd0-e39f976c64df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "can you make bread? Will. Where you in the equire of thing, you can a gransfvattation,  don’t low any existence: that’s\n"
          ]
        }
      ],
      "source": [
        "prompt(model, 'can you make bread?')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "ZjratEf4hD_A"
      ],
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "52bcc07383d658a5785e1b30540c2b504a08802f2f344862f0e6cac62839057c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
